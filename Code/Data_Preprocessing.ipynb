{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "### This notebook contains pre-processing the data, and creating features using TfIdf Vectorizer and Count Vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk as nk\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from collections import Counter\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer,SnowballStemmer\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Note: Change the path of the below files as per your folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"/Users/Purvank/Desktop/MACHINE LEARNING IIT/CS595_ML/Project/Additional_Files/ride_data1.csv\")\n",
    "data2 = pd.read_csv(\"/Users/Purvank/Desktop/MACHINE LEARNING IIT/CS595_ML/Project/Additional_Files/ride_data2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data1,data2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_review</th>\n",
       "      <th>ride_rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I had just completed running the New York Mara...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My appointment time for auto repairs required ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whether I am using Uber for a ride service or ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why is it so hard for you to understand that i...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was in South Beach, FL. I was staying at a m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ride_review  ride_rating  sentiment\n",
       "0  I had just completed running the New York Mara...          1.0          0\n",
       "1  My appointment time for auto repairs required ...          1.0          0\n",
       "2  Whether I am using Uber for a ride service or ...          1.0          0\n",
       "3  Why is it so hard for you to understand that i...          1.0          0\n",
       "4  I was in South Beach, FL. I was staying at a m...          1.0          0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### Remove Stopwords, words with the same root, not alphabetic words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the path of the below file as per your folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "with open(\"/Users/Purvank/Desktop/MACHINE LEARNING IIT/CS595_ML/Project/Additional_Files/stopwords_stanford\") as f:\n",
    "    stanford_sw = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stanford_sw = [x.strip() for x in stanford_sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sw = list(set(stopwords + stanford_sw + list(stop_words.ENGLISH_STOP_WORDS)))\n",
    "sw = [x.lower() for x in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer,LancasterStemmer,SnowballStemmer\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(text):\n",
    "    sb = SnowballStemmer(\"english\")\n",
    "    for i in range(0,len(text['ride_review'])):\n",
    "        tokens = word_tokenize(text['ride_review'].iloc[i])\n",
    "        tokens = [x.lower() for x in tokens if x.lower() not in sw]\n",
    "        tokens = list(filter(lambda x:x.isalpha(),tokens))\n",
    "        stem_tokens = [sb.stem(x) for x in tokens]\n",
    "        c = Counter()\n",
    "        c.update(stem_tokens)\n",
    "        d = dict(c)\n",
    "        seen = set()\n",
    "        result = []\n",
    "        for item in tokens:\n",
    "            if sb.stem(item) not in seen:\n",
    "                seen.add(sb.stem(item))\n",
    "                result.append(item)\n",
    "        review = ' '.join(x for x in result)\n",
    "        text['ride_review'].iloc[i] = review\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/purvank/anaconda3/lib/python3.5/site-packages/pandas/core/indexing.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "pro_data = data_preprocessing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed new requested let tell started right driver agreed pick drop locations called spoke know actually blocked pickup away race road got notification rider joining spoken shortly passenger went wrong moments continuing destination phone asked going claimed need confused far time clearly played dumb saying understand works middle strange wanting argue lucrative jerk peacefully exited stood private residence shivering cold degree rainy weather dark mile safe seek rest warmth safety sooner scrawling fare piece paper standing outside meet inkling conscientiousness nerve charge partial excited using taxis coming lyft connected minutes long warm dressed clothes weary expecting stranded pace wait main traffic heavy rode closures able realistic eternal happiness arrived delivered nicely day finding way file complaint sent couple hours replied wet blanket apology inconvenience offered credit make worse taken wrote corrected harm previous good reputation earned pay preserve relationships better certainly dangerous situation mention discipline told experiences past years bad apple ruined forever'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_data['ride_review'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TfIdf features using TfIdf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(ngram_range=(1,3),min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1 = tf_idf.fit_transform(pro_data[\"ride_review\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_data1 = pd.DataFrame(d1,columns=tf_idf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sb = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "stem_tokens = [sb.stem(x) for x in tf_idf.get_feature_names()]\n",
    "c = Counter()\n",
    "c.update(stem_tokens)\n",
    "d = dict(c)\n",
    "deleted = []\n",
    "print (type(tf_idf.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = list(tf_idf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seen = set()\n",
    "result = []\n",
    "for item in a:\n",
    "    if sb.stem(item) not in seen:\n",
    "        seen.add(sb.stem(item))\n",
    "        result.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_data2 = n_data1[result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1344, 1563)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/purvank/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "n_data2['sentiment'] = pro_data['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1344, 1564)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#n_data1['sentiment'] = pro_data['sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Note: Please change the path of the file as per your folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_data2.to_csv(\"/Users/Purvank/Desktop/MACHINE LEARNING IIT/CS595_ML/Project/Additional_Files/tf_idf.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Binarized features using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,3),min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d2 = cv.fit_transform(pro_data['ride_review']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_data3 = pd.DataFrame(d2,columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "stem_tokens = [sb.stem(x) for x in tf_idf.get_feature_names()]\n",
    "c = Counter()\n",
    "c.update(stem_tokens)\n",
    "d = dict(c)\n",
    "deleted = []\n",
    "print (type(tf_idf.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = list(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seen = set()\n",
    "result = []\n",
    "for item in a:\n",
    "    if sb.stem(item) not in seen:\n",
    "        seen.add(sb.stem(item))\n",
    "        result.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_data4 = n_data3[result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/purvank/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "n_data4['sentiment'] = pro_data['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1344, 1564)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Note: Please change the path of the file as per your folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_data4.to_csv(\"/Users/Purvank/Desktop/MACHINE LEARNING IIT/CS595_ML/Project/Additional_Files/count_vectorizer.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## End of Ipython Notebook"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
